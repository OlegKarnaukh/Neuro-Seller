from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
from openai import OpenAI
from prompts import META_AGENT_PROMPT, generate_seller_prompt
import re
import uuid
import requests
from bs4 import BeautifulSoup

app = FastAPI(title="Neuro-Seller API", version="1.0.0")

# CORS –¥–ª—è Base44
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://app.base44.com", "https://*.base44.com", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI –∫–ª–∏–µ–Ω—Ç
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∏–∞–ª–æ–≥–æ–≤ (–≤ –ø–∞–º—è—Ç–∏, –¥–ª—è MVP)
conversations = {}
agents = {}

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class Message(BaseModel):
    user_id: str
    message: str
    files: List[str] = []

class AgentTest(BaseModel):
    agent_id: str
    message: str

class AgentSave(BaseModel):
    agent_id: str

@app.get("/")
def read_root():
    return {
        "message": "Neuro-Seller API is running! üöÄ",
        "endpoints": {
            "health": "/health",
            "constructor": "/api/constructor-chat",
            "test_agent": "/api/test-agent",
            "save_agent": "/api/save-agent"
        }
    }

@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "service": "neuro-seller-api",
        "version": "1.0.0"
    }

@app.post("/api/constructor-chat")
def constructor_chat(data: Message):
    """–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∞–≥–µ–Ω—Ç–∞ - –¥–∏–∞–ª–æ–≥ —Å –º–µ—Ç–∞-–∞–≥–µ–Ω—Ç–æ–º"""
    
    user_id = data.user_id
    message = data.message
    files = data.files
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
    if user_id not in conversations:
        conversations[user_id] = {
            "history": [],
            "agent_data": {},
            "agent_id": None,
            "collected_info": {
                "business_type": "",
                "services": [],
                "website_content": "",
                "objections": []
            }
        }
    
    collected = conversations[user_id]["collected_info"]
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if files:
        for file_url in files:
            try:
                file_content = extract_file_content(file_url)
                collected["services"].append(f"–ò–∑ —Ñ–∞–π–ª–∞: {file_content}")
            except Exception as e:
                pass
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
    urls = extract_urls(message)
    website_info = ""
    
    if urls:
        for url in urls:
            try:
                site_content = parse_website(url)
                collected["website_content"] = site_content
                website_info = f"\n\n[–°–ò–°–¢–ï–ú–ê: –ò–∑—É—á–∏–ª —Å–∞–π—Ç {url}. –°–æ–¥–µ—Ä–∂–∏–º–æ–µ:\n{site_content[:1000]}...]"
            except Exception as e:
                website_info = f"\n\n[–°–ò–°–¢–ï–ú–ê: –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–∞–π—Ç–∞ {url}: {str(e)}]"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–π—Ç–µ –∫ —Å–æ–æ–±—â–µ–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_message_with_context = message
    if website_info:
        user_message_with_context += website_info
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
    conversations[user_id]["history"].append({
        "role": "user",
        "content": user_message_with_context
    })
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è OpenAI
    messages = [
        {"role": "system", "content": META_AGENT_PROMPT}
    ] + conversations[user_id]["history"]
    
    try:
        # –í—ã–∑–æ–≤ OpenAI API
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7,
            max_tokens=1200
        )
        
        assistant_message = response.choices[0].message.content
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        conversations[user_id]["history"].append({
            "role": "assistant",
            "content": assistant_message
        })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–µ–≥–æ–≤ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        if "[AGENT_READY]" in assistant_message:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞ –∏–∑ —Ç–µ–≥–æ–≤
            agent_data = extract_agent_data(assistant_message)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π agent_id
            agent_id = str(uuid.uuid4())
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑—å
            conversations[user_id]["agent_data"] = agent_data
            conversations[user_id]["agent_id"] = agent_id
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≥–µ–Ω—Ç–∞
            agents[agent_id] = {
                "agent_data": agent_data,
                "test_history": [],
                "created_by": user_id
            }
            
            # –£–ë–ò–†–ê–ï–ú –í–°–ï –¢–ï–ì–ò –ò–ó –¢–ï–ö–°–¢–ê
            clean_message = remove_tags(assistant_message)
            
            return {
                "response": clean_message,
                "status": "agent_ready",
                "agent_id": agent_id,
                "agent_data": agent_data
            }
        
        return {
            "response": assistant_message,
            "status": "in_progress"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")

@app.post("/api/test-agent")
def test_agent(data: AgentTest):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_id = data.agent_id
    message = data.message
    
    if agent_id in agents:
        agent_data = agents[agent_id]["agent_data"]
        test_history = agents[agent_id]["test_history"]
    elif agent_id in conversations and conversations[agent_id].get("agent_data"):
        agent_data = conversations[agent_id]["agent_data"]
        if "test_history" not in conversations[agent_id]:
            conversations[agent_id]["test_history"] = []
        test_history = conversations[agent_id]["test_history"]
    else:
        raise HTTPException(status_code=404, detail=f"Agent not found: {agent_id}")
    
    seller_prompt = generate_seller_prompt(
        agent_name=agent_data.get("agent_name", "–í–∏–∫—Ç–æ—Ä–∏—è"),
        business_type=agent_data.get("business_type", ""),
        knowledge_base=agent_data.get("knowledge_base", "")
    )
    
    test_history.append({
        "role": "user",
        "content": message
    })
    
    messages = [
        {"role": "system", "content": seller_prompt}
    ] + test_history
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        
        assistant_message = response.choices[0].message.content
        
        test_history.append({
            "role": "assistant",
            "content": assistant_message
        })
        
        return {
            "response": assistant_message,
            "agent_name": agent_data.get("agent_name", "–í–∏–∫—Ç–æ—Ä–∏—è"),
            "status": "success"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")

@app.post("/api/save-agent")
def save_agent(data: AgentSave):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_id = data.agent_id
    
    if agent_id not in agents:
        raise HTTPException(status_code=404, detail="Agent not found")
    
    agent_data = agents[agent_id]["agent_data"]
    
    return {
        "status": "success",
        "message": "Agent saved successfully",
        "agent_id": agent_id,
        "agent_data": agent_data
    }

def extract_agent_data(message: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞ –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    
    agent_data = {}
    
    if "[AGENT_NAME:" in message:
        start = message.find("[AGENT_NAME:") + len("[AGENT_NAME:")
        end = message.find("]", start)
        agent_data["agent_name"] = message[start:end].strip()
    
    if "[BUSINESS_TYPE:" in message:
        start = message.find("[BUSINESS_TYPE:") + len("[BUSINESS_TYPE:")
        end = message.find("]", start)
        agent_data["business_type"] = message[start:end].strip()
    
    if "[KNOWLEDGE_BASE:" in message:
        start = message.find("[KNOWLEDGE_BASE:") + len("[KNOWLEDGE_BASE:")
        end = message.find("]", start)
        agent_data["knowledge_base"] = message[start:end].strip()
    
    return agent_data

def remove_tags(message: str) -> str:
    """–£–±–∏—Ä–∞–µ—Ç –í–°–ï —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–µ–≥–æ–≤
    clean = message
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1: [AGENT_READY]
    clean = re.sub(r'\[AGENT_READY\]', '', clean, flags=re.IGNORECASE)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 2: [AGENT_NAME: ...]
    clean = re.sub(r'\[AGENT_NAME:.*?\]', '', clean, flags=re.IGNORECASE)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 3: [BUSINESS_TYPE: ...]
    clean = re.sub(r'\[BUSINESS_TYPE:.*?\]', '', clean, flags=re.IGNORECASE)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 4: [KNOWLEDGE_BASE: ...]
    clean = re.sub(r'\[KNOWLEDGE_BASE:.*?\]', '', clean, flags=re.IGNORECASE)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 5: [–¢–ï–ì–ò: ...]
    clean = re.sub(r'\[–¢–ï–ì–ò:.*?\]', '', clean, flags=re.IGNORECASE | re.DOTALL)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 6: –õ—é–±—ã–µ —Ç–µ–≥–∏ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö —Å "AGENT", "BUSINESS", "KNOWLEDGE"
    clean = re.sub(r'\[.*?(AGENT|BUSINESS|KNOWLEDGE|–¢–ï–ì).*?\]', '', clean, flags=re.IGNORECASE | re.DOTALL)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    clean = re.sub(r'\n{3,}', '\n\n', clean)
    
    return clean.strip()

def extract_urls(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
    return re.findall(url_pattern, text)

def parse_website(url: str) -> str:
    """–ü–∞—Ä—Å–∏—Ç —Å–∞–π—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã, —Å—Ç–∏–ª–∏, –Ω–∞–≤–∏–≥–∞—Ü–∏—é
        for element in soup(["script", "style", "nav", "footer", "header"]):
            element.decompose()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = soup.get_text()
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        return text[:4000]
        
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–∞: {str(e)}")

def extract_file_content(file_url: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞"""
    
    try:
        response = requests.get(file_url, timeout=10)
        response.raise_for_status()
        
        content_type = response.headers.get('Content-Type', '')
        
        if 'text' in content_type or 'json' in content_type:
            return response.text[:3000]
        else:
            return f"[–§–∞–π–ª —Ç–∏–ø–∞ {content_type}]"
            
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
