from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
from openai import OpenAI
from prompts import META_AGENT_PROMPT, generate_seller_prompt
import re
import uuid
import requests
from bs4 import BeautifulSoup

app = FastAPI(title="Neuro-Seller API", version="1.0.0")

# CORS –¥–ª—è Base44
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://app.base44.com", "https://*.base44.com", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI –∫–ª–∏–µ–Ω—Ç
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∏–∞–ª–æ–≥–æ–≤ (–≤ –ø–∞–º—è—Ç–∏, –¥–ª—è MVP)
conversations = {}  # user_id -> conversation data
agents = {}  # agent_id -> agent data

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class Message(BaseModel):
    user_id: str
    message: str
    files: List[str] = []

class AgentTest(BaseModel):
    agent_id: str
    message: str

class AgentSave(BaseModel):
    agent_id: str

@app.get("/")
def read_root():
    return {
        "message": "Neuro-Seller API is running! üöÄ",
        "endpoints": {
            "health": "/health",
            "constructor": "/api/constructor-chat",
            "test_agent": "/api/test-agent",
            "save_agent": "/api/save-agent"
        }
    }

@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "service": "neuro-seller-api",
        "version": "1.0.0"
    }

@app.post("/api/constructor-chat")
def constructor_chat(data: Message):
    """–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∞–≥–µ–Ω—Ç–∞ - –¥–∏–∞–ª–æ–≥ —Å –º–µ—Ç–∞-–∞–≥–µ–Ω—Ç–æ–º"""
    
    user_id = data.user_id
    message = data.message
    files = data.files
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
    if user_id not in conversations:
        conversations[user_id] = {
            "history": [],
            "agent_data": {},
            "agent_id": None,
            "extracted_info": ""
        }
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if files:
        for file_url in files:
            try:
                file_content = extract_file_content(file_url)
                conversations[user_id]["extracted_info"] += f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ —Ñ–∞–π–ª–∞:\n{file_content}"
            except Exception as e:
                conversations[user_id]["extracted_info"] += f"\n\n[–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}]"
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
    urls = extract_urls(message)
    if urls:
        for url in urls:
            try:
                site_content = parse_website(url)
                conversations[user_id]["extracted_info"] += f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ {url}:\n{site_content}"
                message += f"\n\n[–°–∏—Å—Ç–µ–º–∞: –Ø –∏–∑—É—á–∏–ª —Å–∞–π—Ç {url}]"
            except Exception as e:
                message += f"\n\n[–°–∏—Å—Ç–µ–º–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–∞–π—Ç {url}: {str(e)}]"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
    if conversations[user_id]["extracted_info"]:
        message += conversations[user_id]["extracted_info"]
        conversations[user_id]["extracted_info"] = ""  # –û—á–∏—â–∞–µ–º –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
    conversations[user_id]["history"].append({
        "role": "user",
        "content": message
    })
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è OpenAI
    messages = [
        {"role": "system", "content": META_AGENT_PROMPT}
    ] + conversations[user_id]["history"]
    
    try:
        # –í—ã–∑–æ–≤ OpenAI API
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )
        
        assistant_message = response.choices[0].message.content
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        conversations[user_id]["history"].append({
            "role": "assistant",
            "content": assistant_message
        })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–µ–≥–æ–≤ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        if "[AGENT_READY]" in assistant_message:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞ –∏–∑ —Ç–µ–≥–æ–≤
            agent_data = extract_agent_data(assistant_message)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π agent_id
            agent_id = str(uuid.uuid4())
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑—å user_id -> agent_id
            conversations[user_id]["agent_data"] = agent_data
            conversations[user_id]["agent_id"] = agent_id
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≥–µ–Ω—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            agents[agent_id] = {
                "agent_data": agent_data,
                "test_history": [],
                "created_by": user_id
            }
            
            # –£–ë–ò–†–ê–ï–ú –¢–ï–ì–ò –ò–ó –¢–ï–ö–°–¢–ê –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
            clean_message = remove_tags(assistant_message)
            
            return {
                "response": clean_message,
                "status": "agent_ready",
                "agent_id": agent_id,
                "agent_data": agent_data
            }
        
        return {
            "response": assistant_message,
            "status": "in_progress"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")

@app.post("/api/test-agent")
def test_agent(data: AgentTest):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_id = data.agent_id
    message = data.message
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–≥–µ–Ω—Ç–∞
    if agent_id in agents:
        agent_data = agents[agent_id]["agent_data"]
        test_history = agents[agent_id]["test_history"]
    elif agent_id in conversations and conversations[agent_id].get("agent_data"):
        agent_data = conversations[agent_id]["agent_data"]
        if "test_history" not in conversations[agent_id]:
            conversations[agent_id]["test_history"] = []
        test_history = conversations[agent_id]["test_history"]
    else:
        raise HTTPException(
            status_code=404, 
            detail=f"Agent not found: {agent_id}"
        )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –ø—Ä–æ–¥–∞–≤—Ü–∞
    seller_prompt = generate_seller_prompt(
        agent_name=agent_data.get("agent_name", "–í–∏–∫—Ç–æ—Ä–∏—è"),
        business_type=agent_data.get("business_type", ""),
        knowledge_base=agent_data.get("knowledge_base", "")
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    test_history.append({
        "role": "user",
        "content": message
    })
    
    messages = [
        {"role": "system", "content": seller_prompt}
    ] + test_history
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        
        assistant_message = response.choices[0].message.content
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
        test_history.append({
            "role": "assistant",
            "content": assistant_message
        })
        
        return {
            "response": assistant_message,
            "agent_name": agent_data.get("agent_name", "–í–∏–∫—Ç–æ—Ä–∏—è"),
            "status": "success"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")

@app.post("/api/save-agent")
def save_agent(data: AgentSave):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_id = data.agent_id
    
    if agent_id not in agents:
        raise HTTPException(status_code=404, detail="Agent not found")
    
    agent_data = agents[agent_id]["agent_data"]
    
    return {
        "status": "success",
        "message": "Agent saved successfully",
        "agent_id": agent_id,
        "agent_data": agent_data
    }

def extract_agent_data(message: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞ –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    
    agent_data = {}
    
    if "[AGENT_NAME:" in message:
        start = message.find("[AGENT_NAME:") + len("[AGENT_NAME:")
        end = message.find("]", start)
        agent_data["agent_name"] = message[start:end].strip()
    
    if "[BUSINESS_TYPE:" in message:
        start = message.find("[BUSINESS_TYPE:") + len("[BUSINESS_TYPE:")
        end = message.find("]", start)
        agent_data["business_type"] = message[start:end].strip()
    
    if "[KNOWLEDGE_BASE:" in message:
        start = message.find("[KNOWLEDGE_BASE:") + len("[KNOWLEDGE_BASE:")
        end = message.find("]", start)
        agent_data["knowledge_base"] = message[start:end].strip()
    
    return agent_data

def remove_tags(message: str) -> str:
    """–£–±–∏—Ä–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    
    clean = re.sub(r'\[AGENT_READY\]', '', message)
    clean = re.sub(r'\[AGENT_NAME:.*?\]', '', clean)
    clean = re.sub(r'\[BUSINESS_TYPE:.*?\]', '', clean)
    clean = re.sub(r'\[KNOWLEDGE_BASE:.*?\]', '', clean)
    clean = re.sub(r'\n{3,}', '\n\n', clean)
    
    return clean.strip()

def extract_urls(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
    return re.findall(url_pattern, text)

def parse_website(url: str) -> str:
    """–ü–∞—Ä—Å–∏—Ç —Å–∞–π—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
        for script in soup(["script", "style"]):
            script.decompose()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = soup.get_text()
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        return text[:3000]
        
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–∞: {str(e)}")

def extract_file_content(file_url: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞"""
    
    try:
        response = requests.get(file_url, timeout=10)
        response.raise_for_status()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        content_type = response.headers.get('Content-Type', '')
        
        if 'text' in content_type or 'json' in content_type:
            return response.text[:3000]
        elif 'pdf' in content_type:
            # –î–ª—è PDF –Ω—É–∂–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ PyPDF2 –∏–ª–∏ pdfplumber
            return "[PDF —Ñ–∞–π–ª - —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏]"
        else:
            return f"[–§–∞–π–ª —Ç–∏–ø–∞ {content_type} - —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—á–∏—Ç–∞–Ω–æ]"
            
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
