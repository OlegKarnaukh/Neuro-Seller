from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
from openai import OpenAI
from prompts import META_AGENT_PROMPT, generate_seller_prompt
from database import Database
import re
import uuid
import requests
from bs4 import BeautifulSoup
import logging
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import os

# ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã ...

app = FastAPI(title="Neuro-Seller API", version="1.0.0")

# –î–æ–±–∞–≤—å—Ç–µ –≠–¢–ò –°–¢–†–û–ö–ò:
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def read_root():
    # –í–µ—Ä–Ω—É—Ç—å HTML –≤–º–µ—Å—Ç–æ JSON
    return FileResponse("static/index.html")


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Neuro-Seller API", version="1.0.0")

# CORS –¥–ª—è Base44
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://app.base44.com", "https://*.base44.com", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI –∫–ª–∏–µ–Ω—Ç
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite+aiosqlite:///./agents.db")
db = Database(DATABASE_URL)

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞
conversations = {}

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class Message(BaseModel):
    user_id: str
    message: str
    files: List[str] = []

class AgentTest(BaseModel):
    agent_id: str
    message: str

class AgentSave(BaseModel):
    agent_id: str

@app.on_event("startup")
async def startup():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    await db.init_db()
    logger.info("‚úÖ Database initialized")
    logger.info(f"üìù META_AGENT_PROMPT version: {META_AGENT_PROMPT[:100]}...")

@app.get("/")
def read_root():
    return {
        "message": "Neuro-Seller API is running! üöÄ",
        "version": "2.0",
        "endpoints": {
            "health": "/health",
            "constructor": "/api/constructor-chat",
            "test_agent": "/api/test-agent",
            "save_agent": "/api/save-agent",
            "get_agents": "/api/agents/{user_id}"
        }
    }

@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "service": "neuro-seller-api",
        "version": "2.0",
        "database": "connected"
    }

@app.post("/api/constructor-chat")
def constructor_chat(data: Message):
    """–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∞–≥–µ–Ω—Ç–∞ - –¥–∏–∞–ª–æ–≥ —Å –º–µ—Ç–∞-–∞–≥–µ–Ω—Ç–æ–º"""
    
    user_id = data.user_id
    message = data.message
    files = data.files
    
    logger.info(f"üì© Constructor chat: user_id={user_id}, message={message[:100]}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
    if user_id not in conversations:
        conversations[user_id] = {
            "history": [],
            "agent_data": {},
            "agent_id": None
        }
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
    if files:
        logger.info(f"üìé Processing {len(files)} files")
        for file_url in files:
            try:
                file_content = extract_file_content(file_url)
                message += f"\n\n[–°–ò–°–¢–ï–ú–ê: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞:\n{file_content[:1000]}...]"
                logger.info(f"‚úÖ File processed: {file_url[:50]}")
            except Exception as e:
                logger.error(f"‚ùå File error: {e}")
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫
    urls = extract_urls(message)
    if urls:
        logger.info(f"üîó Found {len(urls)} URLs: {urls}")
        for url in urls:
            try:
                logger.info(f"üåê Parsing website: {url}")
                site_content = parse_website(url)
                message += f"\n\n[–°–ò–°–¢–ï–ú–ê: –ò–∑—É—á–∏–ª —Å–∞–π—Ç {url}. –°–æ–¥–µ—Ä–∂–∏–º–æ–µ:\n{site_content[:2000]}...]"
                logger.info(f"‚úÖ Website parsed successfully. Content length: {len(site_content)}")
            except Exception as e:
                logger.error(f"‚ùå Website parse error: {e}")
                message += f"\n\n[–°–ò–°–¢–ï–ú–ê: –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–∞–π—Ç–∞ {url}: {str(e)}]"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
    conversations[user_id]["history"].append({
        "role": "user",
        "content": message
    })
    
    logger.info(f"üìä History length: {len(conversations[user_id]['history'])}")
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è OpenAI
    messages = [
        {"role": "system", "content": META_AGENT_PROMPT}
    ] + conversations[user_id]["history"]
    
    try:
        # –í—ã–∑–æ–≤ OpenAI
        logger.info("ü§ñ Calling OpenAI API...")
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7,
            max_tokens=1200
        )
        
        assistant_message = response.choices[0].message.content
        logger.info(f"‚úÖ OpenAI response received. Length: {len(assistant_message)}")
        logger.info(f"üìù Response preview: {assistant_message[:200]}")
        
        conversations[user_id]["history"].append({
            "role": "assistant",
            "content": assistant_message
        })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        if "[AGENT_READY]" in assistant_message:
            logger.info("üéâ Agent ready! Extracting data...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            agent_data = extract_agent_data(assistant_message)
            logger.info(f"üìä Extracted agent_data: {agent_data}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –ø—Ä–æ–¥–∞–≤—Ü–∞
            seller_prompt = generate_seller_prompt(
                agent_name=agent_data.get("agent_name", "–í–∏–∫—Ç–æ—Ä–∏—è"),
                business_type=agent_data.get("business_type", ""),
                knowledge_base=agent_data.get("knowledge_base", "")
            )
            
            logger.info(f"üìù Generated seller_prompt length: {len(seller_prompt)}")
            logger.info(f"üìù Seller prompt preview: {seller_prompt[:300]}")
            
            # –°–û–•–†–ê–ù–Ø–ï–ú –í –ë–ê–ó–£ –î–ê–ù–ù–´–•
            import asyncio
            agent_id = asyncio.run(db.create_agent(
                user_id=user_id,
                agent_name=agent_data.get("agent_name", ""),
                business_type=agent_data.get("business_type", ""),
                knowledge_base=agent_data.get("knowledge_base", ""),
                system_prompt=seller_prompt
            ))
            
            logger.info(f"üíæ Agent saved to DB: {agent_id}")
            
            conversations[user_id]["agent_data"] = agent_data
            conversations[user_id]["agent_id"] = agent_id
            
            # –£–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏
            clean_message = remove_tags(assistant_message)
            
            return {
                "response": clean_message,
                "status": "agent_ready",
                "agent_id": agent_id,
                "agent_data": agent_data
            }
        
        return {
            "response": assistant_message,
            "status": "in_progress"
        }
        
    except Exception as e:
        logger.error(f"‚ùå OpenAI API error: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")

@app.post("/api/test-agent")
async def test_agent(data: AgentTest):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_id = data.agent_id
    message = data.message
    
    logger.info(f"üß™ Testing agent: {agent_id}, message: {message[:100]}")
    
    # –ü–û–õ–£–ß–ê–ï–ú –ê–ì–ï–ù–¢–ê –ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•
    agent = await db.get_agent(agent_id)
    
    if not agent:
        logger.error(f"‚ùå Agent not found: {agent_id}")
        raise HTTPException(status_code=404, detail=f"Agent not found: {agent_id}")
    
    logger.info(f"‚úÖ Agent loaded: {agent['agent_name']}")
    logger.info(f"üìù System prompt preview: {agent['system_prompt'][:300]}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if agent_id not in conversations:
        conversations[agent_id] = {"test_history": []}
    
    conversations[agent_id]["test_history"].append({
        "role": "user",
        "content": message
    })
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    messages = [
        {"role": "system", "content": agent["system_prompt"]}
    ] + conversations[agent_id]["test_history"]
    
    try:
        logger.info("ü§ñ Calling OpenAI for agent test...")
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        
        assistant_message = response.choices[0].message.content
        logger.info(f"‚úÖ Agent response: {assistant_message[:200]}")
        
        conversations[agent_id]["test_history"].append({
            "role": "assistant",
            "content": assistant_message
        })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        await db.save_conversation(
            agent_id=agent_id,
            channel="preview",
            messages=conversations[agent_id]["test_history"]
        )
        
        return {
            "response": assistant_message,
            "agent_name": agent["agent_name"],
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"‚ùå OpenAI API error during test: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI API error: {str(e)}")

@app.post("/api/save-agent")
async def save_agent(data: AgentSave):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_id = data.agent_id
    
    agent = await db.get_agent(agent_id)
    
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    
    await db.update_agent_status(agent_id, "active")
    
    logger.info(f"‚úÖ Agent activated: {agent_id}")
    
    return {
        "status": "success",
        "message": "Agent activated successfully",
        "agent_id": agent_id
    }

@app.get("/api/agents/{user_id}")
async def get_user_agents(user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    agents = await db.get_user_agents(user_id)
    
    return {
        "status": "success",
        "count": len(agents),
        "agents": agents
    }

# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

def extract_agent_data(message: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞"""
    
    agent_data = {}
    
    if "[AGENT_NAME:" in message:
        start = message.find("[AGENT_NAME:") + len("[AGENT_NAME:")
        end = message.find("]", start)
        agent_data["agent_name"] = message[start:end].strip()
    
    if "[BUSINESS_TYPE:" in message:
        start = message.find("[BUSINESS_TYPE:") + len("[BUSINESS_TYPE:")
        end = message.find("]", start)
        agent_data["business_type"] = message[start:end].strip()
    
    if "[KNOWLEDGE_BASE:" in message:
        start = message.find("[KNOWLEDGE_BASE:") + len("[KNOWLEDGE_BASE:")
        end = message.find("]", start)
        agent_data["knowledge_base"] = message[start:end].strip()
    
    return agent_data

def remove_tags(message: str) -> str:
    """–£–±–∏—Ä–∞–µ—Ç —Ç–µ–≥–∏"""
    
    clean = message
    clean = re.sub(r'\[AGENT_READY\]', '', clean, flags=re.IGNORECASE)
    clean = re.sub(r'\[AGENT_NAME:.*?\]', '', clean, flags=re.IGNORECASE)
    clean = re.sub(r'\[BUSINESS_TYPE:.*?\]', '', clean, flags=re.IGNORECASE)
    clean = re.sub(r'\[KNOWLEDGE_BASE:.*?\]', '', clean, flags=re.IGNORECASE | re.DOTALL)
    clean = re.sub(r'\[–¢–ï–ì–ò:.*?\]', '', clean, flags=re.IGNORECASE | re.DOTALL)
    clean = re.sub(r'\[.*?(AGENT|BUSINESS|KNOWLEDGE|–¢–ï–ì).*?\]', '', clean, flags=re.IGNORECASE | re.DOTALL)
    clean = re.sub(r'\n{3,}', '\n\n', clean)
    
    return clean.strip()

def extract_urls(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL"""
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
    return re.findall(url_pattern, text)

def parse_website(url: str) -> str:
    """–ü–∞—Ä—Å–∏—Ç —Å–∞–π—Ç"""
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        for element in soup(["script", "style", "nav", "footer", "header"]):
            element.decompose()
        
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        
        return text[:4000]
        
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")

def extract_file_content(file_url: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞"""
    
    try:
        response = requests.get(file_url, timeout=10)
        response.raise_for_status()
        
        content_type = response.headers.get('Content-Type', '')
        
        if 'text' in content_type or 'json' in content_type:
            return response.text[:3000]
        else:
            return f"[–§–∞–π–ª —Ç–∏–ø–∞ {content_type}]"
            
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
